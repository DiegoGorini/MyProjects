{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling with SK-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import PorterStemmer\n",
    "import treetaggerwrapper\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.utils.validation import column_or_1d\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1100,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pd.read_csv('IMDB.csv') # 50,000 labeled {positive, negative} movie reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "5  Probably my all-time favorite movie, a story o...  positive\n",
       "6  I sure would like to see a resurrection of a u...  positive\n",
       "7  This show was an amazing, fresh & innovative i...  negative\n",
       "8  Encouraged by the positive comments about this...  negative\n",
       "9  If you like original gut wrenching laughter yo...  positive"
      ]
     },
     "execution_count": 1102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collection of reviews <- Reviews from the csv\n",
    "collection = [review for review in csv.iloc[:,0]]\n",
    "\n",
    "# 'y' into SKLearn (without OneHotEncoding) <- Sentiments from the csv\n",
    "y = csv.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 1121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is what the raw documents in the collection look like:\n",
    "collection[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBJECTS & SETS\n",
    "\n",
    "# Tokenizer (Regex)\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "# Lemmatizer (TreeTagger)\n",
    "tagger = treetaggerwrapper.TreeTagger(TAGLANG='en')\n",
    "# Stemmer (PorterStemmer)\n",
    "stemmer = PorterStemmer()\n",
    "# Stopwords (NLTK)\n",
    "stopWords = [stemmer.stem(sw) for sw in stopwords.words('english')]\n",
    "# Punctuation (Custom)\n",
    "punct = list(r\"!`\\\"»«',(-....:;<>?)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_corpus(collection):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description: Normalizes each document in a collection to generate a corpus.\n",
    "    \n",
    "    - Input: \n",
    "        A list of raw documents [[doc1], [doc2],..., [docN]] where each doc is a raw string.\n",
    "        \n",
    "    - Output:\n",
    "        A list of processed documents [[doc1], [doc2],..., [docN]] where on each doc\n",
    "        the following operations have been applied:\n",
    "            - Removal of non-alphabetic characters\n",
    "            - Case folding of all words\n",
    "            - Tokenization for each '\\w+'\n",
    "            - Removal of stopwords and punctuation\n",
    "            - Lemmatization & stemming\n",
    "    \"\"\"\n",
    "    \n",
    "    corpus = []\n",
    "    for doc in collection:\n",
    "        # Alphabetization\n",
    "        _doc = re.sub('[^A-Za-z]', ' ', doc)\n",
    "        # Case Folding\n",
    "        _doc = _doc.lower()\n",
    "        # Tokenization\n",
    "        _doc = tokenizer.tokenize(_doc)\n",
    "        # Stop Words\n",
    "        _doc = [word for word in _doc if word not in set(stopWords)]\n",
    "        # Punctuation\n",
    "        _doc = [word for word in _doc if word not in set(punct)]\n",
    "        # Lemmatization\n",
    "        _doc = [re.split(r'\\t', word)[2] for word in tagger.tag_text(_doc)]\n",
    "        # Stemming\n",
    "        _doc = [stemmer.stem(word) for word in _doc]\n",
    "        # Joining\n",
    "        _doc = ' '.join(_doc)\n",
    "        # Appending\n",
    "        if _doc != []:\n",
    "            corpus.append(_doc)\n",
    "    print(\"No. of Documents in the Corpus:\", len(corpus))\n",
    "    \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term-Document Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-Of-Words (BOW) Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bow_matrix(corpus, max_features):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description: Generates a Bag-Of-Words Matrix.\n",
    "    \n",
    "    - Input: A corpus of processed documents [doc1, doc2,..., docN] & a specified number\n",
    "    of maximum features (unique words).\n",
    "    \n",
    "    - Output: A (m x n) bag-of-words matrix, where m is the number of documents in the \n",
    "    corpus and n is the number of specified maximum features.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Model\n",
    "    bow_vectorizer = CountVectorizer(min_df=1,\n",
    "                                     max_features=max_features)\n",
    "    # Fit\n",
    "    bow_vectorizer.fit(corpus)\n",
    "    # Index\n",
    "    index = [\"document{}\".format(i) for i in range(len(corpus))]\n",
    "    # Columns\n",
    "    columns = bow_vectorizer.get_feature_names() # Vocabulary\n",
    "    # DataFrame\n",
    "    bow_matrix = pd.DataFrame(bow_vectorizer.transform(collection).toarray(),\n",
    "                       index=index,\n",
    "                       columns=columns)\n",
    "    \n",
    "    print(\"A\", bow_matrix.shape, \"BOW Matrix has been generated.\\n\")\n",
    "    \n",
    "    return bow_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term Frequency-Inverse Document Frequency (TF-IDF) Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tfidf_matrix(corpus, max_features):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description: Generates a TF-IDF Matrix.\n",
    "    \n",
    "    - Input: A corpus of processed documents [doc1, doc2,..., docN] & a specified number\n",
    "    of maximum features (unique words).\n",
    "    \n",
    "    - Output: A (m x n) TF-IDF matrix, where m is the number of documents in the \n",
    "    corpus and n is the number of specified maximum features.\n",
    "    \"\"\"\n",
    "\n",
    "    # Model\n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df=1,\n",
    "                                       max_features=max_features)\n",
    "    # Fit \n",
    "    tfidf_vectorizer.fit(corpus)\n",
    "    # Index\n",
    "    index = [\"document{}\".format(i) for i in range(len(corpus))]\n",
    "    # Columns\n",
    "    columns = tfidf_vectorizer.get_feature_names() # Vocabulary\n",
    "    # DataFrame\n",
    "    tfidf_matrix = pd.DataFrame(tfidf_vectorizer.transform(collection).toarray(),\n",
    "                       index=index,\n",
    "                       columns=columns) # columns=Vocabulary\n",
    "    \n",
    "    print(\"A\", tfidf_matrix.shape, \"TF-IDF Matrix has been generated.\\n\")\n",
    "    \n",
    "    return tfidf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis (PCA) Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pca_matrix(matrix, n_components):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description: Generates a PCA Matrix.\n",
    "    \n",
    "    - Input: A matrix (BOW or TF-IDF) & a specified number of maximum components\n",
    "    (latent topics).\n",
    "    \n",
    "    - Output: A (m x n) PCA matrix, where m is the number of documents in the \n",
    "    corpus and n is the number of specified maximum components.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Normalization\n",
    "    matrix = matrix - matrix.mean()\n",
    "    # Model\n",
    "    pca = PCA(n_components=n_components)\n",
    "    # Index\n",
    "    index = [\"document{}\".format(i) for i in range(len(matrix))]\n",
    "    # Columns\n",
    "    columns = [\"topic{}\".format(i) for i in range(n_components)]\n",
    "    # DataFrame\n",
    "    pca_matrix = pd.DataFrame(pca.fit_transform(matrix),\n",
    "                           index=index,\n",
    "                           columns=columns)\n",
    "    \n",
    "    print(\"A\", pca_matrix.shape, \"PCA Matrix has been generated.\\n\")\n",
    "    \n",
    "    return pca_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Truncated) Singular Value Decomposition (SVD) Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_svd_matrix(matrix, n_components, n_iter):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description: Generates a (TruncateD) SVD Matrix.\n",
    "    \n",
    "    - Input: A matrix (BOW or TF-IDF), a specified number of maximum components\n",
    "    (latent topics) & the number of iterations of the algorithm over the data.\n",
    "    \n",
    "    - Output: A (m x n) SVD matrix, where m is the number of documents in the \n",
    "    corpus and n is the number of specified maximum components.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Normalization\n",
    "    matrix = matrix - matrix.mean()\n",
    "    # Model\n",
    "    svd = TruncatedSVD(n_components=n_components, n_iter=n_iter)\n",
    "    # Index\n",
    "    index = [\"document{}\".format(i) for i in range(len(matrix))]\n",
    "    # Columns\n",
    "    columns = [\"topic{}\".format(i) for i in range(n_components)]\n",
    "    # DataFrame\n",
    "    svd_matrix = pd.DataFrame(svd.fit_transform(matrix),\n",
    "                           index=index,\n",
    "                           columns=columns)\n",
    "    \n",
    "    print(\"A\", svd_matrix.shape, \"SVD Matrix has been generated.\\n\")\n",
    "    \n",
    "    return svd_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cos_similarities(matrix):\n",
    "    \n",
    "    \"\"\"\n",
    "    Description: Generates Cosine-Similarity Matrix\n",
    "    \n",
    "    - Input: A vectorized matrix (TF-IDF, PCA or SVD).\n",
    "    \n",
    "    - Output: A (m x m) matrix where m is the number of documents in the vectorized\n",
    "    matrix & each element x_ij of the matrix is defined as:\n",
    "    \n",
    "    x_ij = cos(i,j) = dot(i,j) / norm(i)*norm(j)\n",
    "    \"\"\"\n",
    "    \n",
    "    cos_sim_matrix = pd.DataFrame(cosine_similarity(matrix, matrix))\n",
    "    \n",
    "    print(\"A\", cos_sim_matrix.shape, \"Cosine Similarity Matrix has been generated.\\n\")\n",
    "    \n",
    "    return cos_sim_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I use the functions above to generate:\n",
    "    - Corpus (from IMBD)\n",
    "    - BOW Matrix\n",
    "    - TF-IDF Matrix\n",
    "    - PCA Matrix <- TF-IDF Matrix\n",
    "    - SVD Matrix <- TF-IDF Matrix\n",
    "    \n",
    "Then I apply the following algorithms to the data:\n",
    "    - (Multinomial) Naïve Bayes (BOW & TF-IDF)\n",
    "    - Logistic Regression (PCA & SVD)\n",
    "\n",
    "Finally, for each model I calculate the accuracy %. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Documents in the Corpus: 50000\n"
     ]
    }
   ],
   "source": [
    "# Corpus\n",
    "corpus = generate_corpus(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one review have mention watch oz episod hook right thi exactli happen br br first thing strike Oz be it brutal unflinch scene violenc set right word go trust thi show faint heart timid thi show pull punch regard drug sex violenc it hardcor classic use word br br call oz nicknam give oswald maximum secur state penitentari focu mainli emerald citi experiment section prison cell glass front face inward privaci high agenda em citi home mani aryan muslim gangsta latino christian italian irish scuffl death stare dodgi deal shadi agreement never far away br br would say main appeal show due fact go show dare forget pretti pictur paint mainstream audienc forget charm forget romanc oz mess around first episod ever see strike nasti be surreal say be readi watch develop tast oz get accustom high level graphic violenc violenc injustic crook guard sell nickel inmat kill order get away well manner middl class inmat be turn prison bitch due lack street skill prison experi watch oz may becom comfort uncomfort view that get touch dark side'"
      ]
     },
     "execution_count": 1122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is what the processed documents in the corpus look like:\n",
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A (50000, 30000) BOW Matrix has been generated.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# BOW Matrix\n",
    "bow_matrix = generate_bow_matrix(corpus, 30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A (50000, 30000) TF-IDF Matrix has been generated.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF Matrix\n",
    "tfidf_matrix = generate_tfidf_matrix(corpus, 30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A (50000, 1000) PCA Matrix has been generated.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PCA Matrix <- TF-IDF Matrix\n",
    "pca_matrix = generate_pca_matrix(tfidf_matrix, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A (50000, 1000) SVD Matrix has been generated.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVD Matrix <- TF-IDF Matrix\n",
    "svd_matrix = generate_svd_matrix(tfidf_matrix, 1000, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Multinomial) Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def multinomial_NB_classifier(matrix):\n",
    "    \n",
    "    \"\"\"\n",
    "    (Multinomial) Naïve Bayes Classifier.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Splitting Data into Train & Test Set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(matrix, # BOW or TF-IDF\n",
    "                                                        y,\n",
    "                                                        test_size=0.20,\n",
    "                                                        random_state=0)\n",
    "    # Model\n",
    "    naiveBayes = MultinomialNB()\n",
    "    # Fit\n",
    "    naiveBayes.fit(X_train, y_train)\n",
    "    # Predictions\n",
    "    y_pred = naiveBayes.predict(X_test)\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    accuracy = ((cm[0][0] + cm[1][1]) / (cm[0][0] + cm[0][1] + cm[1][0] + cm[1][1])) * 100\n",
    "    \n",
    "    print(\"(Multinomial) Naïve Bayes has been successfully applied to the data.\\n\")\n",
    "    print(\"Confusion Matrix:\\n\\n\", pd.DataFrame(cm))\n",
    "    print(\"\\nAccuracy:\", accuracy, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BOW Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Multinomial) Naïve Bayes has been successfully to the data.\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "       0     1\n",
      "0  4258   777\n",
      "1  1085  3880\n",
      "\n",
      "Accuracy: 81.38 %\n"
     ]
    }
   ],
   "source": [
    "multinomial_NB_classifier(bow_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Multinomial) Naïve Bayes has been successfully to the data.\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "       0     1\n",
      "0  4328   707\n",
      "1  1237  3728\n",
      "\n",
      "Accuracy: 80.56 %\n"
     ]
    }
   ],
   "source": [
    "multinomial_NB_classifier(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def logistic_regression_classifier(matrix):\n",
    "    \n",
    "    \"\"\"\n",
    "    Logistic Regression Classifier.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Splitting Data into Train & Test Set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(matrix, # BOW, TF-IDF, PCA or SVD \n",
    "                                                        y,\n",
    "                                                        test_size=0.20,\n",
    "                                                        random_state=0)\n",
    "    # Model\n",
    "    logisticRegression = LogisticRegression(solver='lbfgs', random_state = 0)\n",
    "    # Fit\n",
    "    logisticRegression.fit(X_train, y_train)\n",
    "    # Predictions\n",
    "    y_pred = logisticRegression.predict(X_test)\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    # Accuracy\n",
    "    accuracy = ((cm[0][0] + cm[1][1]) / (cm[0][0] + cm[0][1] + cm[1][0] + cm[1][1])) * 100\n",
    "    \n",
    "    print(\"Logistic Regression has been successfully applied to the data.\\n\")\n",
    "    print(\"Confusion Matrix:\\n\\n\", pd.DataFrame(cm))\n",
    "    print(\"\\nAccuracy:\", accuracy, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression has been successfully to the data.\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "       0     1\n",
      "0  4058   977\n",
      "1   806  4159\n",
      "\n",
      "Accuracy: 82.17 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_classifier(pca_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVD Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n",
      "       0     1\n",
      "0  4314   721\n",
      "1   612  4353\n",
      "\n",
      "Logistic Regression Accuracy: 86.67 %\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_classifier(svd_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
